{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTlHNJ0n60_r"
      },
      "source": [
        "# SmartCab2\n",
        "----\n",
        "In this computer assignment, we will again use reinforcement learning to train a self-driving cab which will\n",
        "pick up and drop passengers at designated areas. We will use the SARSA algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loonJmU060_s"
      },
      "source": [
        "# Importing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4LC9XNRx60_s"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSLKi1TP60_t"
      },
      "source": [
        "#  Building the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VFcw4bJz60_t"
      },
      "outputs": [],
      "source": [
        "env = gym.make(\"Taxi-v3\").env\n",
        "Nstates = env.observation_space.n\n",
        "Nactions = env.action_space.n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CP6yrdDH60_t"
      },
      "source": [
        "# Initializing different paramters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OyiTR9-V60_t"
      },
      "outputs": [],
      "source": [
        "alpha = 0.1\n",
        "gamma = 0.95\n",
        "epsilon = 0.4\n",
        "epsilon_decay = 0.001\n",
        "Nepisodes = 5000\n",
        "\n",
        "q = np.zeros((Nstates, Nactions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sh_zgqo60_t"
      },
      "source": [
        "# Defining utility functions to be used in the learning process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JxFqdCPC60_t"
      },
      "outputs": [],
      "source": [
        "#Function to choose the next action\n",
        "def choose_action(state,epsilon):\n",
        "    ########################## Your code here ##########################\n",
        "    # Enter code for choosing action in epsilon greedy manner\n",
        "\n",
        "\n",
        "\n",
        "    ########################## End of your code ########################\n",
        "    return action"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "TK0xpyIw60_t"
      },
      "outputs": [],
      "source": [
        "#Function to learn the Q-value\n",
        "def update(state, next_state, reward, action, next_action):\n",
        "    ########################## Your code here ##########################\n",
        "    # you need to update the q function here according SARSA algorithm\n",
        "\n",
        "\n",
        "    ########################## End of your code ########################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw_XCTG360_t"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFMObedl60_t"
      },
      "outputs": [],
      "source": [
        "for i in range(Nepisodes):\n",
        "    if i % 100 == 0:\n",
        "        print(\"-------------------\")\n",
        "        print(\"Running episode\", i)\n",
        "\n",
        "    if epsilon > 0.01:\n",
        "            epsilon -= epsilon_decay\n",
        "\n",
        "    state = env.reset()\n",
        "    action = choose_action(state, epsilon)\n",
        "    done = False\n",
        "\n",
        "\n",
        "\n",
        "    while not done:\n",
        "\n",
        "        #Getting the next state\n",
        "        next_state, reward, done, info = env.step(action)\n",
        "\n",
        "        #Choosing the next action\n",
        "        next_action = choose_action(next_state,epsilon)\n",
        "\n",
        "        #Update Q-value\n",
        "        update(state, next_state, reward, action, next_action)\n",
        "\n",
        "        state,action = next_state,next_action\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "GEg6nSQ160_u"
      },
      "outputs": [],
      "source": [
        "testenv = gym.make('Taxi-v3')\n",
        "testenv = testenv.unwrapped\n",
        "state = testenv.encode(2, 2, 2, 1) # initializing (row, column, pickup, dropoff)\n",
        "testenv.s = state\n",
        "\n",
        "#testenv.render()\n",
        "\n",
        "penalties = 0\n",
        "done = False\n",
        "total_reward = 0\n",
        "total_steps = 0\n",
        "while not done:\n",
        "    ########################## Your code here ##########################\n",
        "    # You need to write how action is being chosen in the evaluation.\n",
        "    # Remember to call your action \"a\", because it is used in the next line.\n",
        "\n",
        "    a =\n",
        "    ########################## End of your code ########################\n",
        "\n",
        "    next_s, reward, done, _, _ = testenv.step(a) # \"a\" is the action\n",
        "\n",
        "    total_reward += reward\n",
        "    total_steps += 1\n",
        "    if reward == -10: # if hitting the wall\n",
        "        penalties += 1\n",
        "\n",
        "    #testenv.render()\n",
        "    state = next_s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzgyLDDM60_u"
      },
      "outputs": [],
      "source": [
        "print(\"Passenger dropped off successfully in after time steps \", total_steps)\n",
        "print(\"Total reward is \", total_reward)\n",
        "print(\"Penalties incurred\", penalties)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}